{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Estimating Harold Zurcher model\n",
    "\n",
    "“Dynamic programming and structural estimation” mini course\n",
    "\n",
    "Fedor Iskhakov\n",
    "\n",
    "Reading: **Rust (1987) \"Optimal Replacement of GMC Bus Engines: An Empirical Model of Harold Zurcher\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bellman equation for the Harold Zurcher problem\n",
    "\n",
    "\\begin{equation}\n",
    "V(x) = \\max_{d\\in C} \\big\\{ u(x,d) + \\beta E\\big[ V(x')\\big|x,d\\big] \\big\\}\n",
    "\\end{equation}\n",
    "\n",
    "$C = \\{0,1\\} = \\{\\text{keep},\\text{replace}\\}$\n",
    "\n",
    "\\begin{equation}\n",
    "    \\ u(x_{t},d_t,\\theta_1)=\\left \\{ \n",
    "    \\begin{array}{ll}\n",
    "        -RC-c(0,\\theta_1) & \\text{if }d_{t}=1 \\\\ \n",
    "        -c(x_{t},\\theta_1) & \\text{if }d_{t}=0%\n",
    "    \\end{array} \\right.\n",
    "\\end{equation}\n",
    "\n",
    "$x_{t+1} \\sim F(x_t,d_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rust assumptions\n",
    "\n",
    "1. Additive separability in preferences (**AS**)\n",
    "\n",
    "$$\n",
    "u(x,\\varepsilon,d) = u(x,d) + \\varepsilon[d],\n",
    "$$\n",
    "\n",
    "2. Conditional independence (**CI**)\n",
    "\n",
    "$$\n",
    "p(x',\\varepsilon'|x,\\varepsilon,d) = q(\\varepsilon'|x')\\cdot \\pi(x'|x,d)\n",
    "$$\n",
    "\n",
    "3. Extreme value Type I (EV1) distribution of $\\varepsilon$ (**EV**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "V(x,\\varepsilon) = \\max_{d\\in C} \\big\\{ u(x,d) + \\beta \n",
    "E\\big[ V(x',\\varepsilon')\\big|x,d\\big]\n",
    "+ \\varepsilon[d] \\big\\}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "v(x,d) = u(x,d) + \\beta E\\big[ V(x',\\varepsilon')\\big|x,d\\big]\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "V(x',\\varepsilon') = \\max_{d\\in C} \\big\\{ v(x',d) + \\varepsilon'[d] \\big\\}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "E\\big[ V(x',\\varepsilon')\\big|x,d\\big] = \n",
    "\\int_{X} \\log \\big( \\exp[v(x',0)] + \\exp[v(x',1)] \\big) \\pi(x'|x,d) dx'\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bellman equation in expected value function space\n",
    "\n",
    "Let $EV(x,d)$ denote the expected value function, then we have\n",
    "\n",
    "\\begin{equation}\n",
    "EV(x,d) = \\int_{X} \\log \\big( \\exp[u(x',0) + \\beta EV(x',0)] + \\exp[u(x',1) + \\beta EV(x',1)] \\big) \\pi(x'|x,d) dx'\n",
    "\\end{equation}\n",
    "\n",
    "In the form of the operator\n",
    "\n",
    "$$\n",
    "T^*(EV)(x,d) \\equiv \\int_{X} \\log \\big( \\exp[u(x',0) + \\beta EV(x',0)] + \\exp[u(x',1) + \\beta EV(x',1)] \\big) \\pi(x'|x,d) dx'\n",
    "$$\n",
    "\n",
    "Solution to the Bellman functional equation $EV(x,d)$ is also a fixed point of $T^*$ operator, $T^*(EV)(x,d)=EV(x,d)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choice probabilities in Zurcher model\n",
    "\n",
    "Once the fixed point is found, the *optimal* choice probability $P(d|x)$ is given by the Logit structure (assumption EV):\n",
    "\n",
    "\\begin{equation}\n",
    "P(d|x) = \n",
    "\\frac{\\exp[v(x,d)]}{\\sum_{d'\\in C} \\exp[v(x,d')]} =\n",
    "\\frac{\\exp[u(x,d) + \\beta EV(x,d)]}{\\sum_{d'\\in C} \\exp[u(x,d') + \\beta EV(x,d')]}\n",
    "\\end{equation}\n",
    "\n",
    "The choice probability serve as the bases for forming the likelihood function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "- Harold Zurcher’s Maintenance records of 162 busses in 8 groups\n",
    "- Monthly observations of mileage on each bus (odometer reading)\n",
    "- Data on maintenance operations:\n",
    "    1. Routine periodic maintenance (i.e. brake adjustment)\n",
    "    2. Replacement or repair at time of failure\n",
    "    3. Major engine overhaul and/or replacement (*the focus of the paper*)\n",
    "    \n",
    "Data on $(x_{i,t},d_{i,t})$ where $x_{i,t}$ is discretized mileage (bin indexes), and $d_{i,t}$ is the observed choice at this mileage for each bus $i$ in each month $t$ \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Likelihood function\n",
    "\n",
    "\\begin{equation}\n",
    "L(\\theta, EV_\\theta) = \\prod_{i=1}^{162}\\prod_{t=2}^{T_i} P(d_{i,t}|x_{i,t}) p(x_{i,t}|x_{i,t-1},d_{i,t-1})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "logL(\\theta,EV_\\theta) = \\sum_{i=1}^{162}\\sum_{t=2}^{T_i} \\big ( \\log P(d_{i,t}|x_{i,t}) + \\log p(x_{i,t}|x_{i,t-1},d_{i,t-1}) \\big)\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MLE estimator\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta^* = \\arg\\max_\\theta logL(\\theta, EV_{\\theta})\n",
    "\\end{equation}\n",
    "\n",
    "Unconstrained optimiztion, but retires the computation of $EV_{\\theta}$ for each value of parameter $\\theta$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested loop\n",
    "\n",
    "**Outer loop** = Hill-climbing algorithm\n",
    "- Likelihood function $L(\\theta,EV_{\\theta})$ is maximized with respect to $\\theta$\n",
    "- Quasi-Newton algorithm with approximation of Hessian (BHHH, BFGS)\n",
    "- Each evaluation of $L(\\theta,EV_{\\theta})$ requires dynamic programming solution for $EV_{\\theta}$\n",
    "\n",
    "**Inner loop** = Fixed point algorithm\n",
    "- Solver for the fixed point of the Bellman operator $EV_{\\theta} = \\Gamma(EV_{\\theta}) $\n",
    "- Successive approximations + Newton-Kantorovich iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Important details\n",
    "\n",
    "1. **Performance:** Newton method to maximize likelihood\n",
    "1. **Numerical stability:** recenter smooth maximum (logsum) and choice probabilities\n",
    "2. **Analytical gradients:** not too hard to compute for inner loop (Frechet derivative) and outer loop (using implicit function theorem and chain rule)\n",
    "3. **Use BHHH:** outer product of gradian approximation for Hessian is always positive semidefinie\n",
    "4. **Further info:** NFXP manual (see `papers\\` directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementation\n",
    "\n",
    "We will code up the estimator in the next lab"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
