{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Solving Harold Zurcher model\n",
    "\n",
    "“Dynamic programming and structural estimation” mini course\n",
    "\n",
    "Fedor Iskhakov\n",
    "\n",
    "Reading: **Rust (1987) \"Optimal Replacement of GMC Bus Engines: An Empirical Model of Harold Zurcher\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bellman equation for the Harold Zurcher problem\n",
    "\n",
    "\\begin{equation}\n",
    "V(x) = \\max_{d\\in C} \\big\\{ u(x,d) + \\beta E\\big[ V(x')\\big|x,d\\big] \\big\\}\n",
    "\\end{equation}\n",
    "\n",
    "$C = \\{0,1\\} = \\{\\text{keep},\\text{replace}\\}$\n",
    "\n",
    "\\begin{equation}\n",
    "    \\ u(x_{t},d_t,\\theta_1)=\\left \\{ \n",
    "    \\begin{array}{ll}\n",
    "        -RC-c(0,\\theta_1) & \\text{if }d_{t}=1 \\\\ \n",
    "        -c(x_{t},\\theta_1) & \\text{if }d_{t}=0%\n",
    "    \\end{array} \\right.\n",
    "\\end{equation}\n",
    "\n",
    "$x_{t+1} \\sim F(x_t,d_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transition matrix for mileage when $d=0$\n",
    "\n",
    "$\\Pi(d=0)_{n x n} = \n",
    "\\begin{pmatrix}\n",
    "\\pi_0 & \\pi_1 & \\pi_2 & 0 & \\cdot & \\cdot & \\cdot & 0 \\\\\n",
    "0 & \\pi_0 & \\pi_1 & \\pi_2 & 0 & \\cdot & \\cdot & 0 \\\\\n",
    "0 & 0 &\\pi_0 & \\pi_1 & \\pi_2 & 0 & \\cdot & 0 \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "0 & \\cdot & \\cdot & 0 & \\pi_0 & \\pi_1 & \\pi_2 & 0 \\\\\n",
    "0 & \\cdot & \\cdot & \\cdot & 0 & \\pi_0 & \\pi_1 & \\pi_2 \\\\\n",
    "0 & \\cdot & \\cdot & \\cdot & \\cdot  & 0 & \\pi_0 & 1-\\pi_0 \\\\\n",
    "0 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot  & 0 & 1\n",
    "\\end{pmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition matrix for mileage, $d=1$\n",
    "\n",
    "$\\Pi(d=1)_{n x n} = \n",
    "\\begin{pmatrix}\n",
    "\\pi_0 & \\pi_1 & \\pi_2 & 0 & \\cdot & \\cdot & \\cdot & 0 \\\\\n",
    "\\pi_0 & \\pi_1 & \\pi_2 & 0 & \\cdot & \\cdot & \\cdot & 0 \\\\\n",
    "\\pi_0 & \\pi_1 & \\pi_2 & 0 & \\cdot & \\cdot & \\cdot & 0 \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\pi_0 & \\pi_1 & \\pi_2 & 0 & \\cdot & \\cdot & \\cdot & 0 \\\\\n",
    "\\pi_0 & \\pi_1 & \\pi_2 & 0 & \\cdot & \\cdot & \\cdot & 0 \\\\\n",
    "\\pi_0 & \\pi_1 & \\pi_2 & 0 & \\cdot & \\cdot & \\cdot & 0 \\\\\n",
    "\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bellman operator\n",
    "\n",
    "Bellman equation can be written as a fixed point equation of the **Bellman operator** in the functional space\n",
    "\n",
    "$$\n",
    "T(V)(x) \\equiv \\max_{d \\in C} \\big\\{ u(x,d) + \\beta E\\big[ V(x') \\big|x,d\\big] \\big\\}\n",
    "$$\n",
    "\n",
    "The Bellman equations is then $ V(x) = T({V})(x) $, with the\n",
    "solution given by the fixed point $ T({V}) = V $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bellman equation in expected value function space\n",
    "\n",
    "Let $EV(x,d)$ denote the expected value function, then we have\n",
    "\n",
    "\\begin{equation}\n",
    "EV(x,d) = \\int_{X} \\log \\big( \\exp[u(x',0) + \\beta EV(x',0)] + \\exp[u(x',1) + \\beta EV(x',1)] \\big) \\pi(x'|x,d) dx'\n",
    "\\end{equation}\n",
    "\n",
    "In the form of the operator\n",
    "\n",
    "$$\n",
    "T^*(EV)(x,d) \\equiv \\int_{X} \\log \\big( \\exp[u(x',0) + \\beta EV(x',0)] + \\exp[u(x',1) + \\beta EV(x',1)] \\big) \\pi(x'|x,d) dx'\n",
    "$$\n",
    "\n",
    "Solution to the Bellman functional equation $EV(x,d)$ is also a fixed point of $T^*$ operator, $T^*(EV)(x,d)=EV(x,d)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to solve Bellman equation\n",
    "\n",
    "**Value function iterations (VFI)** \n",
    "also known as successive approximations\n",
    "\n",
    "1. Start with arbitrary guess for $EV(x,d)$\n",
    "2. Apply $T^*$ operator\n",
    "3. Check for (uniform) convergence\n",
    "4. If not converged to a given level of tolerance, return to step 2, otherwise finish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions to think about\n",
    "\n",
    "- What determines the speed of convergence of the VFI algorithm?\n",
    "- How can we improve the convergence speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class zurcher():\n",
    "    '''Harold Zurcher bus engine replacement model class, VFI version'''\n",
    "\n",
    "    def __init__(self, \n",
    "                 n = 175, # default parameter values\n",
    "                 mmax = 450,\n",
    "                 p = [0.0937,0.4475,0.4459,0.0127],\n",
    "                 RC = 11.7257,\n",
    "                 c = 2.45569,\n",
    "                 beta = 0.9999):\n",
    "        '''Initializator for the zurcher class'''\n",
    "        assert sum(p)<=1.0,'sum of transision probability parameters must not exceed unity'\n",
    "        self.p = p        # parameters for transision probabilities\n",
    "        self.n = n        # set number of grid points on the state space\n",
    "        self.mmax = mmax  # maximum milage\n",
    "        self.RC = RC      # replacement cost\n",
    "        self.c = c        # cost function parameter\n",
    "        self.beta = beta  # discount factor\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        '''Dimension getter'''\n",
    "        return self.__n # internal dimension variable\n",
    "\n",
    "    @n.setter\n",
    "    def n(self,n):\n",
    "        '''Dimension setter, updaing the grid and transision probabilities'''\n",
    "        self.__n = n\n",
    "        # create gid for the set dimension\n",
    "        self.grid = np.arange(n) # 0,..,n-1 index of grid points\n",
    "        # create transition prob for the set dimension\n",
    "        p = self.p # \"copy\" the list of parameters\n",
    "        p.append(1.0-sum(p)) # add the last element to ensure 1.0 in sum\n",
    "        self.P1,self.P2 = self.transition_probability(np.array(p)) # compute transision probabilities\n",
    "        \n",
    "    def __str__(self):\n",
    "        '''String representation of the Zurcher model object'''\n",
    "        # id() is unique identifier for the variable (reference), convert to hex\n",
    "        return 'Zurcher bus engine replacement model with id=%s' % hex(id(self))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        '''Print for Zurcher model object'''\n",
    "        return self.__str__()\n",
    "\n",
    "    def transition_probability(self,p):\n",
    "        '''Compute transition probability matrixes conditional on choice'''\n",
    "        # conditional on d=0, no replacement\n",
    "        P1 = np.full((self.n,self.n),0.0)\n",
    "        for i in range(self.n):\n",
    "            if i <= self.n-p.size:\n",
    "                # lines where p vector fits entirely\n",
    "                P1[i][i:i+p.size]=p\n",
    "            else:\n",
    "                P1[i][i:] = p[:self.n-p.size-i]\n",
    "                P1[i][-1] = 1.0-P1[i][:-1].sum()\n",
    "        # conditional on d=1, replacement\n",
    "        P2 = np.full((self.n,self.n),0.0)\n",
    "        for i in range(self.n):\n",
    "            P2[i][:p.size]=p\n",
    "        return P1,P2\n",
    "        \n",
    "    def bellman(self,ev0,output=0):\n",
    "        ''' Bellman operator for the model\n",
    "            Input: current approximation of the EV as column vector\n",
    "                   output = type of output requested \n",
    "            Output: new approximation of EV\n",
    "                    d=0 choice probability (if output>0)\n",
    "                    Frechet derivative of Bellman operator (if output>1)\n",
    "        '''\n",
    "        # EV0 is current approximation of EV on the fixed grid\n",
    "        # For d=0 it holds values for all mileages\n",
    "        # For d=1 (replacement) we use the first value EV0[0]\n",
    "        # So, instead of EV(x,d) for d=0,1, we can use only one vector!\n",
    "        assert np.all(ev0.shape==(self.n,1)),'Expecting EV as column vector'\n",
    "        x = self.grid.reshape((-1,1)) # states (in the next period), column vector\n",
    "        c = 0.001*self.c*x # maintenance cost in all states\n",
    "        v0 = -c + self.beta*ev0 # value of not replacing\n",
    "        v1 = -c[0] -self.RC + self.beta*ev0[0] # value of replacing\n",
    "        # recenter the values for numerical stability of logsum !!!!!!!!!!!!!!!!\n",
    "        maxv = np.maximum(v0,v1)\n",
    "        logsum = maxv + np.log(np.exp(v0-maxv) + np.exp(v1-maxv))\n",
    "        ev1 = self.P1 @ logsum # matrix multiplication, result as column vector\n",
    "        if output == 0:\n",
    "            return ev1\n",
    "        # keep (no replacement) choice probability\n",
    "        pk = 1/(1+np.exp(v1-v0))\n",
    "        if output == 1:\n",
    "            return ev1,pk\n",
    "        # Frechet derivative\n",
    "        dev1 = self.beta * self.P1 * pk.transpose()\n",
    "        dev1[:,0] += self.beta * np.squeeze(self.P1 @ (1-pk))\n",
    "        return ev1,pk,dev1\n",
    "\n",
    "    def solve_vfi(self, maxiter=1000, tol=1e-6, callback=None):\n",
    "        '''Solves the model using successive approximations (VFI)'''\n",
    "        ev0 = np.full((self.n,1),0) # initial guess of EV\n",
    "        for iter in range(maxiter):\n",
    "            ev1,pk = self.bellman(ev0,output=1)\n",
    "            stp = np.max(abs(ev1-ev0))\n",
    "            if callback:\n",
    "                if iter==0: stp0=1.0\n",
    "                callback(iter,self,ev1,pk,stp,stp/stp0) # callback for making plots\n",
    "            if stp < tol: \n",
    "                break\n",
    "            ev0=ev1\n",
    "            stp0=stp\n",
    "        else:  # when i went up to maxiter\n",
    "            print('No convergence: maximum number of iterations achieved!')\n",
    "        return ev1,pk\n",
    "\n",
    "    def solve_nk(self, maxiter=1000, tol=1e-6, callback=None):\n",
    "        '''Solves the model using the Newton-Kantorovich algorithm'''\n",
    "        ev0 = np.full((self.n,1),0) # initial guess of EV\n",
    "        for iter in range(maxiter):\n",
    "            ev1,pk,dev = self.bellman(ev0,output=2) # compute Frechet derivative\n",
    "            ev1 = ev0 - np.linalg.inv(np.eye(self.n)-dev) @ (ev0 - ev1) # NK iteration\n",
    "            stp = np.max(abs(ev1-ev0))\n",
    "            if callback:\n",
    "                if iter==0: stp0=1.0\n",
    "                callback(iter,self,ev1,pk,stp,stp/stp0) # callback for making plots\n",
    "            if stp < tol: \n",
    "                break\n",
    "            ev0=ev1\n",
    "            stp0=stp\n",
    "        else:  # when i went up to maxiter\n",
    "            print('No convergence: maximum number of iterations achieved!')\n",
    "        ev1,pk = self.bellman(ev1,output=1) # compute choice probabilities after convergence\n",
    "        return ev1,pk\n",
    "    \n",
    "    def solve_poly(self, \n",
    "                   maxiter=1000, \n",
    "                   tol=1e-10, \n",
    "                   sa_min=5,         # minimum number of contraction steps\n",
    "                   sa_max=25,         # maximum number of contraction steps\n",
    "                   switch_tol=0.05,  # tolerance of the switching rule\n",
    "                   callback=None, \n",
    "                   verbose=False):\n",
    "        '''Solves the model using the poly-algorithm'''\n",
    "        if verbose: \n",
    "            print('Running solution polyalgorithm')\n",
    "            print('%6s %2s %16s %16s'%('iter','','err','err/err'))\n",
    "        ev0 = np.full((self.n,1),0) # initial guess of EV\n",
    "        for iter in range(maxiter):\n",
    "            if iter==0: stp0=1.0\n",
    "            ev1,pk,dev = self.bellman(ev0,output=2) # SA step\n",
    "            itertype='SA'\n",
    "            if iter>=sa_min and iter>0: # maybe switch to NK?\n",
    "                if abs(stp/stp0 - self.beta)<switch_tol or iter>=sa_max:\n",
    "                    ev1 = ev0 - np.linalg.inv(np.eye(self.n)-dev) @ (ev0 - ev1) # NK step\n",
    "                    itertype='NK'\n",
    "            stp = np.max(abs(ev1-ev0))\n",
    "            if verbose: \n",
    "                print('%6d %2s %16.10f %16.10f'%(iter,itertype,stp,stp/stp0))\n",
    "            if callback:\n",
    "                if iter==0: stp0=1.0\n",
    "                callback(iter,self,ev1,pk,stp,stp/stp0) # callback for making plots\n",
    "            if stp < tol: \n",
    "                break\n",
    "            ev0=ev1\n",
    "            stp0=stp\n",
    "        else:  # when i went up to maxiter\n",
    "            print('No convergence: maximum number of iterations achieved!')\n",
    "        ev1,pk = self.bellman(ev1,output=1) # compute choice probabilities after convergence\n",
    "        return ev1,pk\n",
    "    \n",
    "    \n",
    "    def solve_show(self,solver='vfi',maxiter=1000,tol=1e-6,**kvargs):\n",
    "        '''Illustrate solution'''\n",
    "        fig1, (ax1,ax2) = plt.subplots(1,2,figsize=(14,8))\n",
    "        ax1.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "        ax2.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "        ax1.set_xlabel('Mileage grid')\n",
    "        ax2.set_xlabel('Mileage grid')\n",
    "        ax1.set_title('Value function')\n",
    "        ax2.set_title('Probability of keeping the engine')\n",
    "        def callback(iter,mod,ev,pk,stp,dstp):\n",
    "            if iter==0:\n",
    "                print('%4s %16s %16s'%('iter','err','err(i)/err(i-1)'))\n",
    "                print('-'*40)\n",
    "            print('%4d %16.12f %16.12f'%(iter,stp,dstp))            \n",
    "            ax1.plot(mod.grid,ev,color='k',alpha=0.25)\n",
    "            ax2.plot(mod.grid,pk,color='k',alpha=0.25)\n",
    "        if solver=='vfi':\n",
    "            ev,pk = self.solve_vfi(maxiter=maxiter,tol=tol,callback=callback,**kvargs)\n",
    "        elif solver=='nk':\n",
    "            ev,pk = self.solve_nk(maxiter=maxiter,tol=tol,callback=callback,**kvargs)\n",
    "        elif solver=='poly':\n",
    "            ev,pk = self.solve_poly(maxiter=maxiter,tol=tol,callback=callback,**kvargs)\n",
    "        else:\n",
    "            print('Unknown solver')\n",
    "            return None\n",
    "        # add solutions\n",
    "        ax1.plot(self.grid,ev,color='r',linewidth=2.5)\n",
    "        ax2.plot(self.grid,pk,color='r',linewidth=2.5)\n",
    "        plt.show()\n",
    "        return ev,pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# investigate how parts of the code work:\n",
    "model = zurcher(RC=.5,n=12,p=[0.65,0.2,0.1]) # model instance\n",
    "# model = zurcher() # model instance\n",
    "print('Model grid:\\n',model.grid)\n",
    "print(model) # string representation\n",
    "print('Transition probabilities conditional on not replacing:\\n',model.P1)\n",
    "print('Transition probabilities conditional on replacing:\\n',model.P2)\n",
    "ev,pk=model.bellman(np.full((model.n,1),0),output=1)\n",
    "print('Bellman one run:\\n',ev)\n",
    "print('Probability of keeping:\\n',pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# solve Harold Zurcher model for different parameters\n",
    "m = zurcher(beta=0.9,RC=5.0)\n",
    "ev,pk = m.solve_show(maxiter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convergence of the VFI solution\n",
    "\n",
    "- On one hand: **globally convergent (with single fixed point)**\n",
    "- On the other hand: **very slowly approaching the fixed point when $\\beta$ is close to one**\n",
    "\n",
    "What can we do to make an improvement?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Another approach\n",
    "\n",
    "Remember that the solution of the problem (in terms of expected value function EV) is given by\n",
    "\n",
    "$$\n",
    "T^*(EV)(x,d)=EV(x,d)\n",
    "$$\n",
    "\n",
    "**Because this is an equation, we can try to solve it as an equation as well!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Refresher about the Newton method\n",
    "\n",
    "Solve the equation $g(x)=0$, for now assume $x\\in\\mathbb{R}^1$\n",
    "\n",
    "*Yet, it does work with system of non-linear equations as well!*\n",
    "\n",
    "1. Start with some good guess $ x_0 $ not too far from the solution\n",
    "2. Newton step\n",
    "$$\n",
    "x_{i+1} = x_i - \\frac{g(x_i)}{g'(x_i)} \n",
    "$$\n",
    "3. Iterate until convergence in some metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Derivation for Newton method using Taylor series expansion\n",
    "\n",
    "$$\n",
    "g(x) = \\sum_{k=0}^{\\infty} \\frac{g^{(k)}(x_0)}{k!} (x-x_0)^k\n",
    "$$\n",
    "\n",
    "Take first two terms, assume $ g(x) $ is solution, and let\n",
    "$ x_0=x_i $ and $ x=x_{i+1} $\n",
    "\n",
    "$$\n",
    "0 = g(x) = g(x_i) + g'(x_i) (x_{i+1}-x_i) \\quad \\Rightarrow \\quad x_{i+1} = x_i - \\frac{g(x_i)}{g'(x_i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: solve the equation\n",
    "\n",
    "$$\n",
    "g(x)=-4x^3 + 5x +1 = 0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "-4x^3 + 5x +1 &=& 0 \\\\\n",
    "-4x(x^2-1) + x+1 &=& 0 \\\\\n",
    "(x+1)(-4x^2+4x+1) &=& 0 \\\\\n",
    "\\big(x+1\\big)\\big(x-\\frac{1}{2}-\\frac{1}{\\sqrt{2}}\\big)\\big(x-\\frac{1}{2}+\\frac{1}{\\sqrt{2}}\\big) &=& 0\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def newton(fun, grad, x0, tol=1e-12, maxiter=100, callback=None):\n",
    "    '''Newton method to solve fun(x)=0\n",
    "       Callback function arguments (iter,x,x1,err)\n",
    "    '''\n",
    "    x=x0\n",
    "    for iter in range(maxiter):\n",
    "        x1 = x - fun(x)/grad(x)\n",
    "        err = np.abs(x1-x)\n",
    "        if callback:\n",
    "            callback(iter,x,x1,err)\n",
    "        if err < tol:\n",
    "            return x1\n",
    "        x = x1\n",
    "    else:\n",
    "        raise(RuntimeError('Failed to converge, increase maxiter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def callback_function(iter,x,x1,err):\n",
    "    if iter==0:\n",
    "        print('%4s %16s %16s %6s'%('iter','x','x1','err'))\n",
    "        print('-'*50)\n",
    "    print('%4d %16.12f %16.12f %6.2e'%(iter,x,x1,np.abs(x-x1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "g = lambda x: -4*x**3+5*x+1\n",
    "h = lambda x: -12*x**2+5    # gradient\n",
    "x0 = 2.5 \n",
    "root = newton(g,h,x0,tol=1e-9,callback=callback_function)\n",
    "print('Solution is ',root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_newton(fun,grad,x0,xlim=[0,1],steps=10,**kwargs):\n",
    "    '''Illustration for the Newton method'''\n",
    "    xd = np.linspace(xlim[0],xlim[1],1000)\n",
    "    graph = [xd,fun(xd)]\n",
    "    def show(iter,x,x1,err):\n",
    "        '''callback to make plots'''\n",
    "        if iter >= steps: return\n",
    "        fig1, ax1 = plt.subplots(1,1,figsize=(10,8))\n",
    "        ax1.plot(xlim,[0,0],c='grey')\n",
    "        ax1.plot(graph[0],graph[1],c='red')\n",
    "        fn = fun(x)\n",
    "        ax1.scatter(x,0,c='green')\n",
    "        ax1.plot([x,x],[0,fn],c='grey')\n",
    "        if x!=x1:\n",
    "            l = lambda z: fn*(z - x1)/(x-x1)\n",
    "            ax1.plot(graph[0],l(graph[0]),c='blue')\n",
    "        ax1.scatter(x1,0,c='blue')\n",
    "        ax1.set_xlim(xlim)\n",
    "        ax1.grid(True)\n",
    "        ax1.set_title('Step %d'%iter)\n",
    "        plt.show()\n",
    "    return newton(fun,grad,x0,callback=show,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x0 = 2.5 # try 1, 0.5 (!), 0.63, -0.63, -0.65\n",
    "x0 = 0.75\n",
    "root = show_newton(g,h,x0,tol=1e-8,xlim=[-2,2])\n",
    "print('Solution is ',root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions to think about\n",
    "\n",
    "- Does Newton method always converge?\n",
    "- Which solution does the Newton method converge to?\n",
    "- What determines the speed of convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Back to Harold Zurcher\n",
    "\n",
    "Let's apply Newton method for the equation\n",
    "\n",
    "$$\n",
    "EV(x,d) = \\Gamma(EV)(x,d) \\quad\\Leftrightarrow\\quad (I - \\Gamma)(EV)(x,d)=\\mathbb{0}\n",
    "$$\n",
    "\n",
    "where the new operator is the difference between the identity operator $I$ and Bellman operator $\\Gamma = T^*$, and\n",
    "$\\mathbb{0}$ is zero function\n",
    "\n",
    "**Quadratic convergence!**\n",
    "\n",
    "$$\n",
    "|| EV_{k+1} - EV* || < c ||EV_{k} - EV*||^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Newton-Kantorovich method\n",
    "\n",
    "Kantorovich extended Newton method to functional equations.\n",
    "\n",
    "The NK iteration is \n",
    "\n",
    "$$\n",
    "EV_{k+1} = EV_{k} - (I-\\Gamma')^{-1} (I-\\Gamma)(EV_k)\n",
    "$$\n",
    "\n",
    "Here $I-\\Gamma'$ is a Frechet derivative of the operator $I-\\Gamma$\n",
    "\n",
    "- In terms of finite dimensional approximation, $\\Gamma'$ is an n-by-n matrix of $\\Gamma(ev)$ n-by-1 vector differentiated with $ev$ n-by-1 vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Explore convergence of NK method\n",
    "m = zurcher(beta=0.95,RC=5.0)\n",
    "ev,pk = m.solve_show(maxiter=1000,solver='nk')\n",
    "# ev,pk = m.solve_show(maxiter=1000,solver='vfi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Poly algorithm\n",
    "\n",
    "- NK method may not be convergent at the initial point\n",
    "- Successive apprizimataion (SA) iterations, however, are always convergent\n",
    "\n",
    "**Poly algorithm** is combination of SA and NK:\n",
    "\n",
    "1. Start with SA iterations\n",
    "2. At approximately optimal time switch to NK iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When to switch to NK iterations?\n",
    "\n",
    "Suppose $EV_{k-1} = EV + C$ (where $EV$ is the fixed point)\n",
    "\n",
    "$$\n",
    "err_{k} = ||EV_{k-1}-EV_{k}|| = ||EV+C - T^*(EV+C)|| = ||EV + C - EV - \\beta C|| = C (1-\\beta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "err_{k+1} = ||EV_{k}-EV_{k+1}|| = ||T^*(EV+C) - T^*(T^*(EV+C))|| = ||EV + \\beta C - EV - \\beta^2 C|| = \\beta C (1-\\beta)\n",
    "$$\n",
    "\n",
    "- Then the ration of two errors $err_{k+1} \\big/ err_{k} = \\beta$ when the current apprximation is a constant away from the fixed point.\n",
    "\n",
    "- NK iteration will immeditely \"strip away\" the constant\n",
    "\n",
    "**Thus, switch to NK iteration when $err_{k+1} \\big/ err_{k}$ is close to $\\beta$**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Explore convergence of poly altorithm\n",
    "m = zurcher(beta=0.95,RC=5.0)\n",
    "polyset = {'verbose':True,\n",
    "           'maxiter':1000,\n",
    "           'tol':1e-12,\n",
    "           'sa_min':5,\n",
    "           'sa_max':10,\n",
    "           'switch_tol':0.05,\n",
    "          }\n",
    "ev,pk = m.solve_poly(**polyset)\n",
    "ev,pk = m.solve_show(maxiter=1000,solver='poly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Next: form the MLE estimator\n",
    "\n",
    "- Embed the polyalgorithm into the optimization loop over the parameter $\\theta$\n",
    "- Use quasi-Newton method to maximize the likelihood\n",
    "- BHHH is a great way to approximate the Hessian needed for numerical optimization\n",
    "- Provide analytical derivatives of the likelihood w.r.t. paramters $\\theta$\n",
    "- Use implicit function theorem to compute the derivative of the fixed point w.r.t. paramters $\\theta$\n",
    "- Reuse the Frechet derivative of Bellman operator using the chain rule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"_static/nfxp_manual.png\" style=\"width:800px;\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
